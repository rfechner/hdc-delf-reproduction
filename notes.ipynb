{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1189eb70",
   "metadata": {},
   "source": [
    "## Partially reproducing \"Hyperdimensional computing as a framework for systematic aggregation of image descriptors\"\n",
    "\n",
    "Peer Neubert and Stefan Schubert published a novel application of High Dimensional Computing (HDC) to the domain of Image Description. In their paper \"Hyperdimensional computing as a framework for systematic aggregation of image descriptors\", they apply the HDC-framework, which works by defining an approximate algebraic field with useful operations for descriptor aggregation, to a Mobile Robot Localization Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ee75ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['descriptors/OxfordRobotCar/2015-05-19-14-06-38/delf.mat',\n",
       " 'descriptors/OxfordRobotCar/2014-12-09-13-21-02/delf.mat',\n",
       " 'descriptors/OxfordRobotCar/2014-11-25-09-18-32/delf.mat',\n",
       " 'descriptors/OxfordRobotCar/2015-08-28-09-50-22/delf.mat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root = 'descriptors/OxfordRobotCar/'\n",
    "dates = os.listdir(root)\n",
    "matfiles = [os.path.join(root, date, 'delf.mat') for date in dates]\n",
    "matfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f39e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "data = {mf : scipy.io.loadmat(mf) for mf in matfiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296da9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy as np\n",
    "def __pprint(d : dict | Any) -> str:\n",
    "    if not isinstance(d, dict):\n",
    "        if isinstance(d, np.ndarray):\n",
    "            return f'Array {d.shape}'\n",
    "        else:\n",
    "            return str(d)\n",
    "    else:\n",
    "        kvs = {str(k) : __pprint(v) for k, v in d.items()}\n",
    "        return \"Dict: \\n\" + \"\\n\".join(\"\\t\" + k + \":\" + v for k, v in kvs.items())\n",
    "def pprint(d : dict):\n",
    "    print(__pprint(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ecce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict: \n",
      "\t__header__:b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Thu Nov  5 05:16:59 2020'\n",
      "\t__version__:1.0\n",
      "\t__globals__:[]\n",
      "\tY:Array (1, 2253)\n"
     ]
    }
   ],
   "source": [
    "pprint(data['descriptors/OxfordRobotCar/2014-11-25-09-18-32/delf.mat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f5323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "def order(matlab_objects : dict[str, np.ndarray]) -> dict[str, Tuple[np.ndarray, ...]]:\n",
    "    \"\"\"\n",
    "        Returns numpy arrays for each matlab file for easier handling.\n",
    "    \"\"\"\n",
    "    ret = {}\n",
    "    for sourcefile, matlab_object in matlab_objects.items():\n",
    "        data = matlab_object['Y'].squeeze()\n",
    "        # small research on DELF - DELF returns keypoints (x, y) (or (y, x) ?), scores (s) which\n",
    "        # are presumably attention scores and descriptors.\n",
    "        keypoints, scores, descriptors = \\\n",
    "            np.stack(arrays=data['keypoints'], dtype=np.float32), \\\n",
    "            np.stack(arrays=data['scores'], dtype=np.float32), \\\n",
    "            np.stack(arrays=data['descriptors'], dtype=np.float32)\n",
    "        ret[sourcefile] = (keypoints, scores, descriptors)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cceea216",
   "metadata": {},
   "outputs": [],
   "source": [
    "npdata = order(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4a283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1acb3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptors/OxfordRobotCar/2015-05-19-14-06-38/delf.mat [(1967, 200, 2), (1967, 200, 1), (1967, 200, 1024)]\n",
      "descriptors/OxfordRobotCar/2014-12-09-13-21-02/delf.mat [(2133, 200, 2), (2133, 200, 1), (2133, 200, 1024)]\n",
      "descriptors/OxfordRobotCar/2014-11-25-09-18-32/delf.mat [(2253, 200, 2), (2253, 200, 1), (2253, 200, 1024)]\n",
      "descriptors/OxfordRobotCar/2015-08-28-09-50-22/delf.mat [(1991, 200, 2), (1991, 200, 1), (1991, 200, 1024)]\n"
     ]
    }
   ],
   "source": [
    "_ = [print(key, [x.shape for x in npdata[key]]) for key in npdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e07d0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a look at ground truth files to see what we're trying to map to\n",
    "gtroot = \"ground_truth/OxfordRobotCar/\"\n",
    "gtfiles = [os.path.join(gtroot, filename, 'gt.mat') for filename in os.listdir(gtroot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fd8a620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-08-28-09-50-22/gt.mat',\n",
       " 'ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-05-19-14-06-38/gt.mat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a9eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def _read_h5_dataset(obj):\n",
    "    \"\"\"Convert an h5py object (dataset or group) into a Python object.\"\"\"\n",
    "    \n",
    "    # Case 1: HDF5 Dataset → NumPy array\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        data = obj[()]  # read entire dataset\n",
    "        \n",
    "        # Decode byte strings\n",
    "        if isinstance(data, bytes):\n",
    "            return data.decode(\"utf-8\")\n",
    "        if isinstance(data, np.ndarray) and data.dtype.kind == 'S':\n",
    "            return data.astype(str)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    # Case 2: HDF5 Group → dict (MATLAB struct)\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        result = {}\n",
    "        for key in obj.keys():\n",
    "            result[key] = _read_h5_dataset(obj[key])\n",
    "        return result\n",
    "\n",
    "    # Fallback\n",
    "    return obj\n",
    "\n",
    "\n",
    "def load_mat_v7_3(filepath):\n",
    "    \"\"\"Load MATLAB v7.3 .mat file into a nested Python dictionary.\"\"\"\n",
    "    result = {}\n",
    "    with h5py.File(filepath, \"r\") as f:\n",
    "        for key in f.keys():\n",
    "            result[key] = _read_h5_dataset(f[key])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6269c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtdata = [\n",
    "    load_mat_v7_3(file) for file in gtfiles\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d5bf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-08-28-09-50-22/gt.mat',\n",
       " 'ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-05-19-14-06-38/gt.mat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f19161fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['GThard', 'GThard_cmd', 'GTsoft', 'GTsoft_cmd', 'Info', 'version'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtdata[0]['GT'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2cb6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1991, 2133)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtdata[0]['GT']['GThard'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a512af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1967, 2133)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtdata[1]['GT']['GThard'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38f36c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.uint64(2983), np.uint64(34809))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtdata[0]['GT']['GThard'].sum(), gtdata[0]['GT']['GTsoft'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e871b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtdata = {f : v for f, v in zip(gtfiles, gtdata)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4cae38",
   "metadata": {},
   "source": [
    "### Notes\n",
    "seems like the ground truth is a matrix n x m where n is the \n",
    "number of training samples in 2014-12-09 and m is the number of test\n",
    "samples in 2015-05-19. When training sample i matches test sample j, we\n",
    "get 1 else 0. - check whether this is correct intuition.\n",
    "hard ground truth is (almost) exact image matches and soft ground truth\n",
    "is ~about same location image match?\n",
    "\n",
    "- candidates reproduce HDC-DELF rows:\n",
    "- DB: 2014-12-09 Query: 2015-05-19 -- 0.91\n",
    "- DB: 2015-05-19 Query: 2014-12-09 -- not given in table\n",
    "- DB: 2014-12-09 Query: 2015-08-28 -- 0.71\n",
    "- DB: 2015-08-28 Query: 2014-12-09 -- not given in table\n",
    "\n",
    "thought: WOuld the test-metrics for swapping DB and Query set be identical? This would explain\n",
    "why there are only 6 rows in the table (3 + 2 + 1 comparisons between 4 datasets)\n",
    "- Counter example: very unbalanced train/test datasets - The performance wouldn't be symmetric.\n",
    "- Also I've noticed that there is \"2014-12-16-18-44-24\" dataset which isn't present in the data.\n",
    "- I can only reproduce 2014-12-09 Query: 2015-05-19 -- 0.91, 2014-12-09 Query: 2015-08-28 -- 0.71"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc252529",
   "metadata": {},
   "source": [
    "### Requirements:\n",
    "\n",
    "- get image width/height to do the positional encodings \n",
    "    - just search for the dataset and validate with positions from data\n",
    "    - Visited: https://robotcar-dataset.robots.ox.ac.uk/datasets/\n",
    "    - Looking for Specific dates of our datasets:\n",
    "        - 2014-12-09:\n",
    "            - multiple image resolutions: \n",
    "            1280x960, 1024x1024\n",
    "        - 2015-05-19:\n",
    "            - multiple image resolutions: \n",
    "            1280x960, 1024x1024\n",
    "    - take another look at paper to see whether i can find info.\n",
    "    - It's likely the front camera with resolution 1280x960, that's at least the image i could find in the paper.\n",
    "    - check:\n",
    "        - compute max over keypoints over all training data.\n",
    "        - For 2014-12-09 this gives (np.float32(928.0), np.float32(1248.0))\n",
    "        - => Keypoints are in range (960, 1280) (height, width)\n",
    "\n",
    "- implement the positional encoding scheme.\n",
    "    - take another look at the paper. I think they just use random vectors.\n",
    "- implement the gaussian random projection to project DELF vectors into higher dimension.\n",
    "- think about evaluation protocol. \n",
    "    - We're always setting one dataset as database set, another as query set.\n",
    "    - We're computing matching scores for each database sample and choose the one with highest score as prediction\n",
    "    - THen, we're looking up the ground truth table to see whether position (i, j) == 1\n",
    "    - We get accuracy scores for hard ground truth and soft ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b617ed79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(928.0), np.float32(1248.0))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = npdata['descriptors/OxfordRobotCar/2014-12-09-13-21-02/delf.mat'][0]\n",
    "np.amax(d[..., 0], axis=(0, 1)), np.amax(d[..., 1], axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c654b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My current memory is completely filled. Let's save these datasets to file and delete them from memory.\n",
    "import pickle\n",
    "with open('DB_2014-12__Q_2015-05.pickle', 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'db' : npdata['descriptors/OxfordRobotCar/2014-12-09-13-21-02/delf.mat'],\n",
    "        'query' : npdata['descriptors/OxfordRobotCar/2015-05-19-14-06-38/delf.mat'],\n",
    "        'gt' : {\n",
    "            'hard' : gtdata['ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-05-19-14-06-38/gt.mat']['GT']['GThard'],\n",
    "            'soft' : gtdata['ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-05-19-14-06-38/gt.mat']['GT']['GTsoft']\n",
    "        }\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "462e3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DB_2014-12__Q_2015-08.pickle', 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'db' : npdata['descriptors/OxfordRobotCar/2014-12-09-13-21-02/delf.mat'],\n",
    "        'query' : npdata['descriptors/OxfordRobotCar/2015-08-28-09-50-22/delf.mat'],\n",
    "        'gt' : {\n",
    "            'hard' : gtdata['ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-08-28-09-50-22/gt.mat']['GT']['GThard'],\n",
    "            'soft' : gtdata['ground_truth/OxfordRobotCar/2014-12-09-13-21-02--2015-08-28-09-50-22/gt.mat']['GT']['GTsoft']\n",
    "        }\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137be251",
   "metadata": {},
   "outputs": [],
   "source": [
    "del npdata, gtdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b08a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embed import nx, ny, xb, yb, binsizex, binsizey, w, h, d, bxs, bys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xb, binsizex) # ==> keypoints will never lie on internal border\n",
    "print(yb, binsizey) # ==> keypoints may lie on internal border..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a96a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(x : int, y : int):\n",
    "    # Bin x, y into bins to get indices\n",
    "    # This digitize behaviour is weird. I'll cover edgecases.\n",
    "    xi, yi = np.digitize(x, xb) - 1, np.digitize(y, yb) - 1\n",
    "    xi, yi = min(max(0, xi), nx - 1), min(max(0, yi), ny - 1) # in case point lies on edge...\n",
    "    Bxl, Bxr = bxs[xi], bxs[xi + 1]\n",
    "    Byl, Byr = bys[yi], bys[yi + 1] # left/right maps to up/down in world coordinates and low/high in image coordinates.\n",
    "    \n",
    "    delta_x_l = x % int(binsizex) # approximate\n",
    "    delta_x_r = binsizex - delta_x_l\n",
    "    delta_y_l = y % int(binsizey) # exact\n",
    "    delta_y_r = binsizey - delta_y_l\n",
    "\n",
    "    # print('delta_x_l: ', delta_x_l, ' delta_x_r: ', delta_x_r)\n",
    "    # print('delta_y_l: ', delta_y_l, ' delta_y_r: ', delta_y_r)\n",
    "    \n",
    "    alpha_x = int(np.round(d * delta_x_r / binsizex))\n",
    "    alpha_y = int(np.round(d * delta_y_r / binsizey))\n",
    "\n",
    "    # print('alphax: ', alpha_x, ' alphay: ', alpha_y)\n",
    "    X = np.concat([Bxl[:alpha_x], Bxr[alpha_x:]])\n",
    "    Y = np.concat([Byl[:alpha_y], Byr[alpha_y:]])\n",
    "    P = X * Y\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: lets repeat the heatmap plot from the paper:\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "anchor = (900, 500)\n",
    "xi, yi = np.meshgrid(np.linspace(0, w, 100), np.linspace(0, h, 100))\n",
    "anchor_embedding = positional_encoding(*anchor)\n",
    "other_embeddings = np.stack([positional_encoding(x, y) for x, y in zip(xi.flatten(), yi.flatten())])\n",
    "similarities = np.array([cosine(anchor_embedding, other) for other in other_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc69042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_grid = similarities.reshape(100, 100)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(sim_grid, origin='lower', aspect='auto')\n",
    "plt.scatter(anchor[0] / w * 100, anchor[1] / h * 100, color='red', marker='*', s=200)\n",
    "plt.colorbar(label=\"Cosine distance\")\n",
    "plt.title(\"Positional Encoding Cosine Distance Heatmap\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8896f",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "- seems to be working alright enough to continue.\n",
    "- nextup: gaussian random projection.\n",
    "    -> read up on wiki/chatgpt\n",
    "    -> sklearn library for random projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "mock_data = np.random.choice([-1, 1], size=(100, 1024))\n",
    "grp = GaussianRandomProjection(n_components=d)\n",
    "xs = grp.fit_transform(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cadaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the vectors are still almost orthogonal:\n",
    "# make histogram over the cosines between vectors:\n",
    "\n",
    "distances = np.stack([np.stack([cosine(x, y) for j, x in enumerate(xs) if i != j]) for i, y in enumerate(xs)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35764754",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distances, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423afbb1",
   "metadata": {},
   "source": [
    "Distances are still far from each other. Seems okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f26710",
   "metadata": {},
   "outputs": [],
   "source": [
    "del grp, mock_data, xs, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b6300",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Now i have everything to conduct the experiment. Plan:\n",
    "- load in the datasets (database, query, ground truths)\n",
    "- define an embedding function for feature descriptor\n",
    "    -> fit_transform with the GaussianRandomProjection object from sklearn\n",
    "    -> Returns feat := [num_samples, batch, data] tensor\n",
    "- re-use embedding function for position\n",
    "    -> Returns pos := [num_samples, batch, data] tensor\n",
    "- define function for entangling and storing data\n",
    "    -> Should just feat * pos, then sum over batch dimension. We're left with [num_samples, data] tensor\n",
    "- Do the same for the query set.\n",
    "- Define a function which returns the index of the best match in database.\n",
    "    -> whats the evaluation protocol in the paper like? Anyways, i cannot majority vote because i have no labels for data.\n",
    "    -> could instead do recall analysis.\n",
    "    -> save for later.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5048c0",
   "metadata": {},
   "source": [
    "### Note\n",
    "Due to OOM I'm computing the encodings of the database and query in a python script and load in the data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed6978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db96d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001525165226232842 0.04931367564819522\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1967 is out of bounds for axis 1 with size 1967",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     db, query, gts \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m     10\u001b[0m gt_hard, gt_soft \u001b[38;5;241m=\u001b[39m gts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mT, gts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_hard\u001b[49m\u001b[43m)\u001b[49m, evaluate(db, query, gt_soft))\n",
      "File \u001b[0;32m~/github/hdc-delf-reproduction/evaluate.py:20\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(db, query, gts)\u001b[0m\n\u001b[1;32m     18\u001b[0m inners \u001b[38;5;241m=\u001b[39m db_norm \u001b[38;5;241m@\u001b[39m query_norm\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# [N, M]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m winners \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(inners, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [M]\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m truepos \u001b[38;5;241m=\u001b[39m \u001b[43mgts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwinners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     21\u001b[0m acc \u001b[38;5;241m=\u001b[39m truepos \u001b[38;5;241m/\u001b[39m query\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1967 is out of bounds for axis 1 with size 1967"
     ]
    }
   ],
   "source": [
    "with open('preprocessed-DB_2014-12__Q_2015-05.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))\n",
    "with open('preprocessed-DB_2014-12__Q_2015-08.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5f2be",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "- I'm assuming the reported accuracy was on the soft ground truth for now.\n",
    "- There is still a discrepancy between the accuracies.\n",
    "    - I'm currently sampling from {-1, 1} not [-1, 1]\n",
    "    - I'm not normalizing per image yet.\n",
    "- Lets repeat the evaluations, but lets implement the two changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a597c",
   "metadata": {},
   "source": [
    "### Normalized over feature dimension (per-image), sampling from [-1, 1]\n",
    "\n",
    "- calculating the mean, std per image, then normalizing\n",
    "- applied before gaussian random projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp2-preprocessed-DB_2014-12__Q_2015-05.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))\n",
    "\n",
    "with open('exp2-preprocessed-DB_2014-12__Q_2015-08.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff2a67",
   "metadata": {},
   "source": [
    "### Normalized over num_samples + feature dimension\n",
    "\n",
    "- collecting the mean, std from the database set. We're calculating the mean over the first two dimensions (num_samples, features)\n",
    "- applying before gaussian random projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp3-preprocessed-DB_2014-12__Q_2015-05.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))\n",
    "\n",
    "with open('exp3-preprocessed-DB_2014-12__Q_2015-08.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c671239",
   "metadata": {},
   "source": [
    "### Normalize over feature dimension after Gaussian Random Projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp4-preprocessed-DB_2014-12__Q_2015-05.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))\n",
    "\n",
    "with open('exp4-preprocessed-DB_2014-12__Q_2015-08.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43561771",
   "metadata": {},
   "source": [
    "### Further Ideas\n",
    "\n",
    "- why not try to use unbinding in the classification process.\n",
    "    - Currently $L_i = \\sum_j^M P_j \\odot F_j$. We aren't using the score for each feature here.\n",
    "    - We could instead $L_i = \\sum_j^M P_j \\odot F_j \\odot I_j$ where $I_j$ is a random vector with role \"j-th highest score\"\n",
    "    - For classification, we could then instead of taking the best match take the top-m matches and unbind the top-f features for comparison\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe35c9c",
   "metadata": {},
   "source": [
    "### Base classification performance with additional Index binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp5-preprocessed-DB_2014-12__Q_2015-05.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))\n",
    "\n",
    "with open('exp5-preprocessed-DB_2014-12__Q_2015-08.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate(db, query, gt_hard), evaluate(db, query, gt_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc337e",
   "metadata": {},
   "source": [
    "### Classification performance with unbind-aware evaluation\n",
    "\n",
    "- we're adding two hyperparameters to the evaluation:\n",
    "    - `topm` the number of best-matches to evaluate against a query sample.\n",
    "    - `topf` the number of top-features to unbind from the bundled vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52613b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from evaluate import evaluate_with_unbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topm, topf = 15, 3\n",
    "with open('exp5-preprocessed-DB_2014-12__Q_2015-05.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate_with_unbind(db, query, gt_hard, topm=topm, topf=topf), evaluate_with_unbind(db, query, gt_soft, topm=topm, topf=topf))\n",
    "\n",
    "with open('exp5-preprocessed-DB_2014-12__Q_2015-08.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate_with_unbind(db, query, gt_hard, topm=topm, topf=topf), evaluate_with_unbind(db, query, gt_soft, topm=topm, topf=topf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topm, topf = 3, 15\n",
    "with open('exp5-preprocessed-DB_2014-12__Q_2015-05.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate_with_unbind(db, query, gt_hard, topm=topm, topf=topf), evaluate_with_unbind(db, query, gt_soft, topm=topm, topf=topf))\n",
    "\n",
    "with open('exp5-preprocessed-DB_2014-12__Q_2015-08.pickle', 'rb') as file:\n",
    "    tmp = pickle.load(file)\n",
    "    db, query, gts = tmp.values()\n",
    "\n",
    "gt_hard, gt_soft = gts['hard'].T, gts['soft'].T\n",
    "print(evaluate_with_unbind(db, query, gt_hard, topm=topm, topf=topf), evaluate_with_unbind(db, query, gt_soft, topm=topm, topf=topf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd7275",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Underwhelming results, perhaps the loss of information by binding and unbinding again is too large? An upper bound for this method would anyways be DELF results with\n",
    "~0.94 and ~0.34 (?) respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
